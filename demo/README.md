[GAN](https://poloclub.github.io/ganlab/)

[ChatGPT is not all you need. A State of the Art
Review of large Generative AI models](https://arxiv.org/pdf/2301.04655.pdf)

# Gallery Dall-e
* [Google Doc  A cat sitting in a chair, wearing a pair of sunglasses](https://docs.google.com/document/d/11WlzjBT0xRpQhP9tFMtxzd0q6ANIdHPUBkMV-YB043U/edit#heading=h.fe0kfnfhh2yf)

* [DALL·E 2 and AI art prompt resources & tools to inspire beautiful images](http://dallery.gallery/prompt-resources-tools-ai-art/)

# [ChatGPT](https://chat.openai.com/chat)

* [demo de chat gpt](https://huggingface.co/spaces/anzorq/chatgpt-demo)
* [ Voice -> text -> chatgpt -> text -> voice ](https://huggingface.co/spaces/sanchit-gandhi/chatGPT)
* [brain Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)

* [Let's build GPT: from scratch, in code, spelled out Video](https://www.youtube.com/watch?v=kCc8FmEb1nY) plus [Colab](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing)

[Hugging Face Transformers Examples](https://www.philschmid.de/huggingface-transformers-examples)

# Demos

[object detection](https://huggingface.co/spaces/ShilongLiu/Grounding_DINO_demo]

[Segment Anything Model (SAM): a new AI model from Meta AI that can "cut out" any object, in any image, with a single click](https://segment-anything.com/)

[Difusao Video + Text Command](https://huggingface.co/spaces/fffiloni/Pix2Pix-Video)

[Text to Audio](https://text-to-audio.github.io/)

[Editando Images com comandos em texto](https://huggingface.co/spaces/timbrooks/instruct-pix2pix) and [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/InstructPix2Pix_using_diffusers.ipynb)

![](https://github.com/arduinoufv/machinelearning/blob/main/demo/Captura%20de%20tela%20de%202023-01-21%2008-03-04.png?raw=true)

[Image Similarity with Hugging Face Datasets and Transformers](https://huggingface.co/blog/image-similarity)

[TorchYolo: YOLO Series Object Detection and Track Algorithm Library](https://huggingface.co/spaces/kadirnar/torchyolo)

[Object Detection with KerasCV](https://keras.io/guides/keras_cv/object_detection_keras_cv/)

[how to use Keras and Diffusion](https://keras.io/guides/keras_cv/generate_images_with_stable_diffusion/)

[Have you ever imagined what a corgi-alike coffee machine or a tiger-alike rabbit would look like? ](https://huggingface.co/spaces/daspartho/MagicMix)

[code generator](https://huggingface.co/spaces/bigcode/santacoder-demo)

[Creating visualizations for presentations sucks.](https://www.chula.ai/)

[Generate article from few words](https://galactica.org/)

[Dream Studio](https://beta.dreamstudio.ai/dream)

[InstructPix2Pix
Learning to Follow Image Editing Instructions](https://www.timothybrooks.com/instruct-pix2pix)
![](https://instruct-pix2pix.timothybrooks.com/man.jpg)


# Gradio Demo

* [Gradio demo for VideoMAE for video classification. To use it, simply upload your video or click one of the examples to load them. Read more at the links below.](https://huggingface.co/spaces/sayakpaul/video-classification-ucf101-subset)
* [Question and Answer](https://huggingface.co/spaces/gradio/question-answering)
* [Yolo v6 Video](https://huggingface.co/spaces/nateraw/yolov6)
* [Anime](https://huggingface.co/spaces/Evel/Evel_Space)
* [Clustering and Sklearn](https://huggingface.co/spaces/scikit-learn/clustering)
* [Vision-and-Language Transformer (ViLT), fine-tuned on VQAv2 ](https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)
* [Extremely-Fast diffusion text-to-speech synthesis pipeline with ProDiff and FastDiff](https://huggingface.co/spaces/Rongjiehuang/ProDiff)
* [Classification and Sklearn](https://huggingface.co/spaces/scikit-learn/classification)
* [How do you draw an owl: 1. draw some circles 2. click "Diffuse the rest"](https://huggingface.co/spaces/huggingface/diffuse-the-rest)
* [Week 1 Project: Building a Leaf Classification App](https://colab.research.google.com/drive/1b50WxRu4qjMuxH2SKgALeuVptBWBHb0q)
* [Drive&Segment: Unsupervised Semantic Segmentation of Urban Scenes via Cross-modal Distillation](https://huggingface.co/spaces/vobecant/DaS)
* [Semantic Segmentation with MobileViT and DeepLabV3](https://huggingface.co/spaces/Matthijs/mobilevit-deeplab-demo)
* [Unsupervised Salient Object Detection with Spectral Cluster Voting](https://huggingface.co/spaces/noelshin/selfmask)
* {CVPR conference click on HF space](https://huggingface.co/spaces/CVPR/CVPR2022_papers)
* [Dall-e mini text to images](https://huggingface.co/spaces/dalle-mini/dalle-mini)
* [Demo list](https://github.com/gradio-app/awesome-demos)
* [Github gradio](https://github.com/gradio-app/gradio/tree/master/demo)
* [Generate mandarin speech from text ](https://huggingface.co/spaces/eugenesiow/mandarin-tts)
* [Text generation complete...](https://huggingface.co/spaces/mrm8488/GPT-J-6B)
* [Small Object Detection with SAHI + YOLOv5](https://huggingface.co/spaces/fcakyon/sahi-yolov5)
* [Vit - Bamboo for Image Recognition Demo (https://github.com/Davidzhangyuanhan/Bamboo). ](https://huggingface.co/spaces/CVPR/Bamboo_ViT-B16_demo)
* **Gradio Blocks examples**
    * [Introduction to Blocks](https://gradio.app/introduction_to_blocks/)
    * [Pypi Dynamic Plots](https://huggingface.co/spaces/huggingface/library-metrics)   
    * [Several Demos](https://huggingface.co/Gradio-Blocks)

# Yolo 

[Yolo demo in Website](https://microsoft.github.io/onnxjs-demo/#/yolo)

# Q&A

[Minerva - wo hundred undergraduate-level problems in physics, biology, chemistry, economics, and other sciences that require quantitative reasoning, and find that the model can correctly answer nearly a third of them. ](https://minerva-demo.github.io/#category=Biology&index=4)
![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjg2pZKEx3fN6YWcrhM2dxOYE6wZNm6ytbSTOl7SmDS0sXAwhBY10MiHa3NQ8JymJwJwwyVLcz5Kh96g9l2UgzBv_OaD-2PLGDMp8oWYcPI6q1d-pTp65ad2QFzK8fMp_l7bNe68qCOmNmwJD-U-_XlJOtjPheooUOv3nDvFMn9VLrO0HrL4WUzFXLsDQ/s16000/image7.gif)

# Generation

[Free GPT3](https://opt.alpa.ai/)

[Keras tutorial Text generation](https://keras.io/examples/nlp/text_generation_gpt/)

[Recent Deep Learning Links + explanations](https://deep-learning-links.carrd.co/)

[Text Abstract to Title](https://huggingface.co/shamikbose89/mt5-small-finetuned-arxiv-cs-finetuned-arxiv-cs-full?text=Natural+language+processing+encompasses+several+tasks%2C+one+of+which+is+the+automaticsimplification+of+texts.+Saying+whether+a+text+is+simpler+than+the+other+involves+not+onlytechnical+knowledge+about+the+language+being+analyzed%2C+but+also+a+cultural+knowledgeof+the+target+audience+to+which+the+text+is+being+directed%2C+making+simplificationan+even+more+complex+task.+In+Brazil%2C+around+30%25+of+the+population%2C+according+tothe+IBGE%2C+cannot+interpret+texts%2C+which+shows+the+importance+of+simplification+sothat+the+information+to+be+transmitted+can+reach+a+greater+number+of+people.+Thecurrent+metrics+used+to+say+how+good+the+simplification+done+by+Artificial+intelligence+algorithms+was%2C+is+based+on+more+consolidated+areas+of+study+in+linguistics%2C+such+astranslation+and+text+summarization%2C+and+may+not+be+appropriate+to+be+applied+in+theanalysis+of+automatic+methods+of+simplification.+In+this+article%2C+we+will+present+a+simplemetric+capable+of+quantifying+the+simplicity%2Fcomplexity+of+a+sentence+that+contributesto+the+task+of+automating+text+simplification+in+the+field+of+NLP.+The+results+of+thetests+performed+indicate+that+the+proposed+metric+has+the+potential+to+be+used+toevaluate+automatic+methods+of+simplification.)

[Image Generation](http://gaugan.org/gaugan2/)

[Imagen unprecedented photorealism × deep level of language understanding](https://imagen.research.google/) + [github&paper](https://github.com/lucidrains/imagen-pytorch)


# GAN...does not exist

* [thispersondoesnotexist](https://thispersondoesnotexist.com/)
* [thispizzadoesnotexist](https://syncedreview.com/2020/12/09/this-pizza-does-not-exist-stylegan2-based-model-generates-photo-realistic-pizza-images/)
* [thishorsedoesnotexist](https://thishorsedoesnotexist.com/)
* [Psychedelics in a Fantasy Land](https://www.youtube.com/shorts/8NuNk7MdWx4)

# Text to/from Images

* [Image Captioning with VirTex model trained on RedCaps](https://huggingface.co/spaces/umichVision/virtex-redcaps)
* [DALL·E: Creating Images from Text](https://openai.com/blog/dall-e/)
* [Merge art Dall-e](https://youtu.be/t1ZVufIVO2c)
* [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)
* [ Chrome extension to read a paper + video](https://gist.github.com/amitness/9e5ad24ab963785daca41e2c4cfa9a82)
* [Image to text DEMO](https://huggingface.co/spaces/EleutherAI/magma)
* [Awesome Text-to-Image - A collection of resources on text-to-image synthesis task.](https://github.com/Yutong-Zhou-cv/Awesome-Text-to-Image)

# Transfer Learning 

* [Knowledge Transfer in Self Supervised Learning](https://amitness.com/knowledge-transfer/)

# Music
* [Ted How AI could compose a personalized soundtrack to your life | Pierre Barreau](https://www.youtube.com/watch?v=wYb3Wimn01s)
* [Bardo Composer](https://soundcloud.com/lucas-ferreira-83/sbbs-example1)
* [I am AI - Aiva](https://www.youtube.com/watch?v=Emidxpkyk6o)
* [Plutonium - Rock Song Composed by AI | AIVA](https://www.youtube.com/watch?v=i2TjTb_Psh8)
* [Among Star](https://www.youtube.com/watch?v=K8UQAh5vHuE)

# Visualize CNN

[An Interactive Node-Link Visualization of Convolutional Neural Networks](https://www.cs.ryerson.ca/~aharley/vis/) MNIST EXAMPLE

# visual effect

[visual effect](http://www.ritsumei.ac.jp/~akitaoka/index-e.html)

# transformers

[This paper trains a Transformer to *directly predict docIDs* given a search query. This means the model weights themselves are the index. What does it mean? And how viable is this for real applications? ](https://www.youtube.com/watch?v=qlB0TPBQ7YY)

[ViT Visual Transformers](https://huggingface.co/spaces/Hila/RobustViT)

# Diffusion and 3D

[Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures](https://github.com/eladrich/latent-nerf)
![](https://github.com/eladrich/latent-nerf/raw/main/docs/car.gif)
[DiffEdit - Semantic Image Editing with Stable Diffusion](https://www.storminthecastle.com/posts/diffedit/) ![](https://www.storminthecastle.com/img/diffedit.png)

[This demo compares VQ-Diffusion-ITHQ and Stable-Diffusion-v1-5 for text to image generation.](https://huggingface.co/spaces/patrickvonplaten/vq-vs-stable-diffusion)

# Nvidia

[AI PLAYGROUND
A Interseção da AI, da Arte e da Ciência.](https://www.nvidia.com/pt-br/research/ai-playground/)


# Multitracking

[Pytorch](https://github.com/open-mmlab/mmtracking)

# Text Generation

[Word-level text generation with Keras in <50 lines of code
Get the IMDB movie review dataset](https://colab.research.google.com/drive/1B9yLXcJ7Q76EUoim-2Xy7Dk1gC1pFdU1)

# AI in 2020
[Andrew NG, December 2020](https://blog.deeplearning.ai/blog/the-batch-biggest-ai-stories-of-2020-covid-triage-fun-with-gans-disinfo-whack-a-mole-gpt-superstar-imagenet-recall-fda-approvals?utm_source=Social&utm_medium=Twitter&utm_campaign=TheBatch_12.23.20)

# Python

[Jina-powered multi-user video chat in 20 lines of code, showcasing how to use Jina for building a real-time streaming solution.](https://github.com/jina-ai/jina-video-chat)
